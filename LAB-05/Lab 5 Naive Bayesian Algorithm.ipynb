{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Na√Øve Bayesian classifier\n",
    "\n",
    "### Aim: \n",
    "To classify Certain data tuple in the csv file to their respective classes (0,1) using Naive Bayesian Classifier.\n",
    "\n",
    "Naive Bayesian Classifier is a Probabilistic Classifier which returns probability of the the data belonging to a certain class. Since it is probabilistic Value it returns value between 0 and 1.\n",
    "\n",
    "### References:\n",
    "1. GeeksforGeeks: https://www.geeksforgeeks.org/naive-bayes-classifiers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read file\n",
    "Read the file from csv, convert each item into floating point number then return the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    file_content = csv.reader(open(filename,'r'))\n",
    "    dataset = list(file_content)\n",
    "    # Convert String to float value\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(line) for line in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data\n",
    "Splitting data into, Training & Testing<br>\n",
    "Training is used to make the model learn & testing data is the one which we want to predict<br>\n",
    "<code>split_ratio</code> is the parameter which specifies how much __percentage of data__ is to be given for __training__<br>\n",
    "Select the lines randomly from dataset to train data, & remaing data will be obviously a testing data<br>\n",
    "Return as list of ```train & test data```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_ratio):\n",
    "    train_len = int(len(dataset) * split_ratio)\n",
    "    train_data = []\n",
    "    test_data = list(dataset)\n",
    "    while len(train_data) < train_len:\n",
    "        # Select one random index and move: test-> train data\n",
    "        index = random.randrange(len(test_data))\n",
    "        train_data.append(test_data.pop(index))\n",
    "    return [train_data, test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get prepare the data\n",
    "Convert a data of type<br>\n",
    "```[attrib1, attrib2 ....attribn, label]``` <br>\n",
    "to<br>```dictionary(label)->[(mean(attrib1),stddev(attrib1)),(mean(attrib1),stddev(attrib1))....(mean(attribn),stddev(attribn))]```.<br>\n",
    "\n",
    "> Hence we need ```mean(numbers)``` as well as ```stdev(numbers)```.<br>\n",
    "Formula, Mean: <img src=\"https://www.gstatic.com/education/formulas/images_long_sheet/mean.svg\" width=\"20%\"/> Standard Deviation :<img src=\"https://www.gstatic.com/education/formulas/images_long_sheet/sample_standard_deviation.svg\" width=\"20%\"/>\n",
    "\n",
    "> ```separateByClass(dataset)``` : converts from list to a dictionary of __class__ and its __X ( attribute list)__.\n",
    "\n",
    "> ```summarizeByClass(dataset)```: gets dataset and converts it into dictionary of __class__ and its __mean and std__ by calling summarize method over result obtained by separateByClass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    varience = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(varience)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summary = [(mean(x), stdev(x)) for x in zip(*dataset)]\n",
    "    # Remove the labels mean and std. no necessary\n",
    "    del summary[-1]\n",
    "    return summary\n",
    "    \n",
    "def separateByClass(dataset):\n",
    "    separate = {}\n",
    "    for vector in dataset:\n",
    "        if vector[-1] not in separate:\n",
    "            separate[vector[-1]] = []\n",
    "        separate[vector[-1]].append(vector)\n",
    "    return separate\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summary = {}\n",
    "    for classLabel, classValue in separated.items():\n",
    "        summary[classLabel] = summarize(classValue)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict\n",
    "Over the test data predict the value using the Naive Bayesian Formula with Normal Distr.\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQYGloOirBzTFgFjY5esv_09Ksikn3NJYN6aErIn_P2BKmsrgZx\" height=\"30%\"/>\n",
    "\n",
    "This formula is implemented in ```calculateProbability(x, mean, stdev)```.\n",
    "\n",
    "### Naive Bayesian Formula:\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRLZnzsVloSpAZU8YTmtzll58CqF0S0oWMjGCgVhUV9nctjNcPa\" height=\"100px\"/>\n",
    "Here the <code>P(c)</code> is multiplied with <code>P(c|x1), P(c|x2)...</code> etc. And the P(c|xi) is calculated by <code>calculateProbability(x, mean, stdev)</code> On each row of dataset.\n",
    "<hr>\n",
    "<b>NOTE :</b>not to include the last column during <code>for i in range(len(testset[0])-1):</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x - mean, 2))/ (2* math.pow(stdev, 2)))\n",
    "    return ( 1 / (math.sqrt(2*math.pi)*stdev ) * exponent)\n",
    "    \n",
    "def calculateClassProbabilities(summary, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summary.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(testset[0])-1):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            # Apply forumla\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "\n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    " \n",
    "def getPredictions(summary, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accuracy\n",
    "Predict by comparing prediction of __Navie Bayesian__ and the __Test Result__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The length of the Data Set :  768\n",
      "\n",
      " Number of Rows in Training Set:537 rows\n",
      "\n",
      " Number of Rows in Testing Set:231 rows\n",
      "\n",
      " Model Summaries:\n",
      " {1.0: [(4.865671641791045, 3.741239044041554), (141.25746268656715, 31.939622058007195), (70.82462686567165, 21.49181165060413), (22.16417910447761, 17.67971140046571), (100.33582089552239, 138.6891247315351), (35.14253731343278, 7.262967242346376), (0.5505, 0.372354483554611), (37.06716417910448, 10.968253652367915)], 0.0: [(3.298, 3.01718458262189), (109.98, 26.14119975535359), (68.184, 18.063075413305828), (19.664, 14.889947113744254), (68.792, 98.86528929231767), (30.30419999999996, 7.689855011650112), (0.42973400000000017, 0.29908530435741093), (31.19, 11.667654791631156)]}\n",
      "\n",
      "Predictions:\n",
      " [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      " Accuracy: 76.62337662337663%\n"
     ]
    }
   ],
   "source": [
    "dataset = load_csv('DATASET/lab5.csv')\n",
    "print(\"\\n The length of the Data Set : \",len(dataset))\n",
    "\n",
    "trainset, testset = split_dataset(dataset, 0.7)\n",
    "print('\\n Number of Rows in Training Set:{0} rows'.format(len(trainset)))\n",
    "print('\\n Number of Rows in Testing Set:{0} rows'.format(len(testset)))\n",
    "\n",
    "summaries = summarizeByClass(dataset)\n",
    "print(\"\\n Model Summaries:\\n\",summaries)\n",
    "\n",
    "predictions = getPredictions(summaries, testset)\n",
    "print(\"\\nPredictions:\\n\",predictions)\n",
    "\n",
    "accuracy = getAccuracy(testset, predictions)\n",
    "print('\\n Accuracy: {0}%'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
